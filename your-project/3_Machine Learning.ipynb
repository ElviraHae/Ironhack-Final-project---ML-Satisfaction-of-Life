{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification ml:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regression ml\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree.export import export_text\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optimize model\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA, FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('./data/datamax_cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsets\n",
    "background = ['PB140: YEAR OF BIRTH','PB150: SEX','PB190: MARITAL STATUS','PB200: CONSENSUAL UNION', 'PB220A: CITIZENSHIP']\n",
    "\n",
    "education = ['PE010: CURRENT EDUCATION ACTIVITY', 'PE040: HIGHEST ISCED LEVEL ATTAINED']\n",
    "\n",
    "work = ['PL031: SELF-DEFINED CURRENT ECONOMIC STATUS', 'PL035: WORKED AT LEAST 1 HOUR DURING THE PREVIOUS WEEK', 'PL051: OCCUPATION (ISCO-08 (COM))', 'PL150: MANAGERIAL POSITION']\n",
    "\n",
    "health = ['PH010: GENERAL HEALTH',\n",
    " 'PH020: SUFFER FROM ANY A CHRONIC (LONG-STANDING) ILLNESS OR CONDITION',\n",
    " 'PH030: LIMITATION IN ACTIVITIES BECAUSE OF HEALTH PROBLEMS',\n",
    " 'PH040: UNMET NEED FOR MEDICAL EXAMINATION OR TREATMENT',\n",
    " 'PH060: UNMET NEED FOR DENTAL EXAMINATION OR TREATMENT']\n",
    "\n",
    "job= ['PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME',\n",
    "       'PY035G: CONTRIBUTIONS TO INDIVIDUAL PRIVATE PENSION PLANS',\n",
    "      'PY080G: PENSION FROM INDIVIDUAL PRIVATE PLANS',\n",
    "      \"PY090G++: SOCIAL BENEFITS\"]\n",
    "jobdiff=['PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME',\n",
    "       'PY035G: CONTRIBUTIONS TO INDIVIDUAL PRIVATE PENSION PLANS',\n",
    "      'PY080G: PENSION FROM INDIVIDUAL PRIVATE PLANS',\n",
    "       'PY090G: UNEMPLOYMENT BENEFITS', 'PY100G: OLD-AGE BENEFITS',\n",
    "       'PY110G: SURVIVORâ€™ BENEFITS', 'PY120G: SICKNESS BENEFITS',\n",
    "       'PY130G: DISABILITY BENEFITS', 'PY140G: EDUCATION-RELATED ALLOWANCES']\n",
    "\n",
    "\n",
    "bneeds= ['PD020: Replace worn-out clothes by some new (not second-hand) ones',\n",
    "       'PD030: Two pairs of properly fitting shoes',\n",
    "       'PD050: Get-together with friends/family (relatives) for a drink/meal at least once a month',\n",
    "       'PD060: Regularly participate in a leisure activity',\n",
    "       'PD070: Spend a small amount of money each week on yourself',\n",
    "       'PD080: Internet connection for personal use at home']\n",
    "\n",
    "\n",
    "sat =['PW010: OVERALL LIFE SATISFACTION', 'PW020: MEANING OF LIFE',\n",
    "       'PW030: SATISFACTION WITH FINANCIAL SITUATION',\n",
    "       'PW040: SATISFACTION WITH ACCOMMODATION', 'PW050: BEING VERY NERVOUS',\n",
    "       'PW060: FEELING DOWN IN THE DUMPS', 'PW070: FEELING CALM AND PEACEFUL',\n",
    "       'PW080: FEELING DOWNHEARTED OR DEPRESSED', 'PW090: BEING HAPPY',\n",
    "       'PW120: SATISFACTION WITH TIME USE',\n",
    "       'PW130: TRUST IN THE POLITICAL SYSTEM',\n",
    "       'PW140: TRUST IN THE LEGAL SYSTEM', 'PW150: TRUST IN THE POLICE',\n",
    "       'PW160: SATISFACTION WITH PERSONAL RELATIONSHIPS',\n",
    "       'PW170: PERSONAL MATTERS (ANYONE TO DISCUSS WITH)',\n",
    "       'PW180: HELP FROM OTHERS', 'PW190: TRUST IN OTHERS',\n",
    "       'PW200: SATISFACTION WITH RECREATIONAL OR GREEN AREAS',\n",
    "       'PW210: SATISFACTION WITH LIVING ENVIRONMENT',\n",
    "       'PW220: PHYSICAL SECURITY']\n",
    "\n",
    "subsets= [background,education,work,health,job,bneeds, sat]\n",
    "columns = []\n",
    "for x in subsets:\n",
    "    for y in x:\n",
    "        columns.append (y)\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Superfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh ds\n",
    "def reload():\n",
    "    return pd.read_csv('./data/datamax_cleaned.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbin(column_to_bin, x):\n",
    "    bin_labels = [x for x in range(0,x)]\n",
    "\n",
    "    equal_bins = pd.cut(ds[column_to_bin], x, labels = bin_labels)\n",
    "    return equal_bins\n",
    "\n",
    "def qbin(column_to_bin, x):\n",
    "    bin_labels = [x for x in range(0,x)]\n",
    "\n",
    "    equal_bins = pd.qcut(ds[column_to_bin], x, labels = bin_labels)\n",
    "    return equal_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned =pbin('PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binned.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 generate train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate tests with several binning\n",
    "# binning first\n",
    "def generateTest (X_interested,y_interested, dummy, drop_na_in_y, scalertouse):\n",
    "    outcome = ds[y_interested]\n",
    "    features = ds[X_interested]\n",
    "    outcomelist=y_interested\n",
    "    featureslist=X_interested\n",
    "    data =pd.merge(features, outcome, left_index=True, right_index=True)\n",
    "    \n",
    "    # create dummy\n",
    "    categorical= ['PB150: SEX', 'PB190: MARITAL STATUS',\n",
    "       'PB200: CONSENSUAL UNION', 'PB220A: CITIZENSHIP',\n",
    "       'PE010: CURRENT EDUCATION ACTIVITY',\n",
    "       'PL031: SELF-DEFINED CURRENT ECONOMIC STATUS',\n",
    "       'PL035: WORKED AT LEAST 1 HOUR DURING THE PREVIOUS WEEK',\n",
    "       'PL051: OCCUPATION (ISCO-08 (COM))', 'PL150: MANAGERIAL POSITION',\n",
    "        'PH030: LIMITATION IN ACTIVITIES BECAUSE OF HEALTH PROBLEMS',\n",
    "       'PH040: UNMET NEED FOR MEDICAL EXAMINATION OR TREATMENT',\n",
    "       'PH060: UNMET NEED FOR DENTAL EXAMINATION OR TREATMENT',\n",
    "       'PD020: Replace worn-out clothes by some new (not second-hand) ones',\n",
    "       'PD030: Two pairs of properly fitting shoes',\n",
    "       'PD050: Get-together with friends/family (relatives) for a drink/meal at least once a month',\n",
    "       'PD060: Regularly participate in a leisure activity',\n",
    "       'PD070: Spend a small amount of money each week on yourself',\n",
    "       'PD080: Internet connection for personal use at home',\n",
    "      ]\n",
    "    \n",
    "\n",
    "\n",
    "    create_dummy=set(featureslist).intersection(categorical)\n",
    "    data_dummy = pd.get_dummies(data, columns=create_dummy, drop_first=True)\n",
    "    if dummy=='yes':\n",
    "        data = data_dummy\n",
    "    \n",
    "    ## drop na in outcome\n",
    "    if drop_na_in_y == 'yes':\n",
    "        data = data[data[outcomelist]>=0]\n",
    "    \n",
    "    ## split dataset again in x and y\n",
    "    XCol=list(data.columns)\n",
    "    XCol.remove(outcomelist)\n",
    "    YCol=outcomelist\n",
    "    Xtouse = data[XCol]\n",
    "    y= data[YCol]\n",
    "\n",
    "    \n",
    "    # scaler\n",
    "    if scalertouse == \"Standard\":\n",
    "        scaler = StandardScaler()\n",
    "        X_ = scaler.fit_transform(Xtouse)\n",
    "    elif scalertouse == \"MinMax\":\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        X_ = scaler.fit_transform(Xtouse)\n",
    "        X_.shape\n",
    "    elif scalertouse == \"Normalizer\":\n",
    "        scaler = Normalizer()\n",
    "        X_ = scaler.fit_transform(Xtouse)\n",
    "        X_.shape\n",
    "    else: \n",
    "        X_ = Xtouse\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2  Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxximize function to split and run all the models:\n",
    "\n",
    "def regmodel (X_interested,y_interested, dummy, drop_na_in_y, scalertouse):\n",
    "\n",
    "    X_train = generateTest (X_interested,y_interested, dummy, drop_na_in_y, scalertouse)[0]\n",
    "    X_test = generateTest (X_interested,y_interested, dummy, drop_na_in_y, scalertouse)[1]\n",
    "    y_train = generateTest (X_interested,y_interested, dummy, drop_na_in_y,  scalertouse)[2]\n",
    "    y_test = generateTest (X_interested,y_interested, dummy, drop_na_in_y, scalertouse)[3]\n",
    "\n",
    "    \n",
    "    print(\"X: \", X_interested)\n",
    "    print(\"Y: \", y_interested,\"\\n\")\n",
    "    \n",
    "    # Linear Regression\n",
    "    lm = LinearRegression()\n",
    "    model = lm.fit(X_train,y_train)\n",
    "\n",
    "    print(\"Intercept: \", lm.intercept_)\n",
    "    print(\"Coef: \", lm.coef_)\n",
    "\n",
    "    y_pred  = lm.predict(X_test)\n",
    "    print (\"linear aMSE: \", mean_absolute_error(y_test, y_pred))\n",
    "    print (\"linear MSE: \",mean_squared_error(y_test, y_pred))\n",
    "    print (\"linear R2: \",r2_score(y_test, y_pred), \"\\n\")\n",
    "    \n",
    "    \n",
    "    ### Regression Tree\n",
    "    regr = DecisionTreeRegressor(random_state = 29)\n",
    "    model = regr.fit(X_train, y_train)\n",
    "    y_pred  = regr.predict(X_test)\n",
    "    regr.score(X_test, y_test)\n",
    "    print (\"Regression Tree aMSE: \", mean_absolute_error(y_test, y_pred))\n",
    "    print (\"Regression Tree MSE: \",mean_squared_error(y_test, y_pred))\n",
    "    print (\"Regression Tree R2: \",r2_score(y_test, y_pred),\"\\n\")\n",
    "    \n",
    "    ### KNeighborsRegressor\n",
    "    knnr = KNeighborsRegressor(n_neighbors = 3)\n",
    "    model = knnr.fit(X_train, y_train)  #fit the model\n",
    "    y_pred = knnr.predict(X_test)\n",
    "    print (\"KNeighbores aMSE: \", mean_absolute_error(y_test, y_pred))\n",
    "    print (\"KNeighbores MSE: \",mean_squared_error(y_test, y_pred))\n",
    "    print (\"KNeighbores R2: \",r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmodel(bneeds,'PW130: TRUST IN THE POLITICAL SYSTEM', 'yes', 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4  Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxximize function to split and run all the models:\n",
    "## y binning first\n",
    "def class_bin (X_interested,y_interested, dummy, drop_na_in_y, scalertouse):\n",
    "\n",
    "    X_train = generateTest (X_interested,y_interested, dummy, drop_na_in_y, scalertouse)[0]\n",
    "    X_test = generateTest (X_interested,y_interested, dummy, drop_na_in_y,  scalertouse)[1]\n",
    "    y_train = generateTest (X_interested,y_interested, dummy, drop_na_in_y,  scalertouse)[2]\n",
    "    y_test = generateTest (X_interested,y_interested, dummy, drop_na_in_y,  scalertouse)[3]\n",
    "\n",
    "    \n",
    "    print(\"X: \", X_interested)\n",
    "    print(\"Y: \", y_interested, \"\\n\")\n",
    "    \n",
    "    # logistic regression\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred=lr.predict(X_test)\n",
    "    conf=confusion_matrix(y_test, y_pred)\n",
    "    #tn,fp,fn,tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    #matrix = pd.DataFrame([[tp, tn, (tp+tn),round((tp+tn)/(tp+tn+fp+fn)*100,2)],[fp, fn, (fp+fn), ]], index = [\"true\", \"false\"], columns=['positive', 'negative', 'total','accuracy'])\n",
    "    #print(matrix)\n",
    "    print( \"Logistic regression - accuracy: \", str(round(lr.score(X_test, y_test)*100,2)))\n",
    "    print( \"Logistic regression - precision\", str(round((conf[0,0])/ (conf[1,0]+conf[0,0])*100,2)), \"\\n\")\n",
    "\n",
    "    # Decision Tree classyier\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    conf=confusion_matrix(y_test, y_pred)\n",
    "    #tn,fp,fn,tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    #matrix = pd.DataFrame([[tp, tn, (tp+tn),round((tp+tn)/(tp+tn+fp+fn)*100,2)],[fp, fn, (fp+fn), ]], index = [\"true\", \"false\"], columns=['positive', 'negative', 'total','accuracy'])\n",
    "    #print(matrix)\n",
    "    print( \"Decision tree - accuracy  \", str(round(dtc.score(X_test, y_test)*100,2)))\n",
    "    print( \"Decision tree - precision\", str(round((conf[0,0])/ (conf[1,0]+conf[0,0])*100,2)), \"\\n\")  \n",
    "      \n",
    "    # super vector machine (takes too much time)                                          \n",
    "                                                   \n",
    "    # KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    conf=confusion_matrix(y_test, y_pred)\n",
    "    #tn,fp,fn,tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    #matrix = pd.DataFrame([[tp, tn, (tp+tn),round((tp+tn)/(tp+tn+fp+fn)*100,2)],[fp, fn, (fp+fn), ]], index = [\"true\", \"false\"], columns=['positive', 'negative', 'total','accuracy'])\n",
    "    print(conf)\n",
    "    print( \"KNeighborsClassifier - accuracy  \", str(round(knn.score(X_test, y_test)*100,2)))\n",
    "    print( \"KNeighborsClassifier - precision\", str(round((conf[0,0])/ (conf[1,0]+conf[0,0])*100,2)), \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_bin(background, 'PW130: TRUST IN THE POLITICAL SYSTEM', 'yes' , 'yes', 'MaxMin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryclass_bin(xes,yli,nrbinx, dummy, drop_na_in_y, scalertouse):\n",
    "    ds=reload()\n",
    "    # x biningfor x in try1:\n",
    "    for x in xes:\n",
    "        if len(ds[x].unique())>nrbinx:\n",
    "               ds[x]=pbin(x,nrbinx)\n",
    "    # y binning\n",
    "    for x in xes: \n",
    "        print(x, ds[x].unique())\n",
    "    ds['binned_y']= pbin(yli,2)\n",
    "    print(ds['binned_y'].unique())\n",
    "    \n",
    "    # run\n",
    "    class_bin (xes,yli, dummy, drop_na_in_y, scalertouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mulit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## target multi\n",
    "# binning first\n",
    "def class_mul (X_interested,y_interested, dummy, drop_na_in_y, scalertouse):\n",
    "    \n",
    "    X_train = generateTest (X_interested,y_interested, dummy, drop_na_in_y, scalertouse)[0]\n",
    "    X_test = generateTest (X_interested,y_interested, dummy, drop_na_in_y, scalertouse)[1]\n",
    "    y_train = generateTest (X_interested,y_interested, dummy, drop_na_in_y,  scalertouse)[2]\n",
    "    y_test = generateTest (X_interested,y_interested, dummy, drop_na_in_y,  scalertouse)[3]\n",
    "\n",
    "    \n",
    "    print(\"X: \", X_interested)\n",
    "    print(\"X: \", y_interested)\n",
    "    \n",
    "    #### b) DecisionTree Classify\n",
    "\n",
    "    dtc = DecisionTreeClassifier()#class_weight='balanced')#max_features=10,\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "\n",
    "    acc = dtc.score(X_test, y_test)*100\n",
    "    print(f\"Decision Tree Test Accuracy {round(acc, 2)}%\")\n",
    " \n",
    "\n",
    "    #### c) Support Vector Maschine\n",
    "    svm = SVC(decision_function_shape='ovo')\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    acc = svm.score(X_test,y_test)*100\n",
    "    print(f\"SVM Algorithm Test Accuracy {round(acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "class_mul(background, sat[0], 'yes' , 'no', 'MaxMin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine binnen y and run modell\n",
    "def tryclass_multi(xes,yli,nrbinx, nrbiny,dummy, drop_na_in_y, scalertouse):\n",
    "    ds=reload()\n",
    "    # x biningfor x in try1:\n",
    "    for x in xes:\n",
    "        if len(ds[x].unique())>nrbinx:\n",
    "               ds[x]=pbin(x,nrbinx)\n",
    "    # y binning\n",
    "    for x in xes: \n",
    "        print(x, ds[x].unique())\n",
    "    ds['binned_y']= pbin(yli,nrbiny)\n",
    "    print(ds['binned_y'].unique())\n",
    "    \n",
    "    # run\n",
    "    class_mul(xes, 'binned_y', dummy, drop_na_in_y, scalertouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryclass_multi(background, sat[3], 2,2,  'yes' , 'no', 'MaxMin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRFE (X_train, y_train, limit): \n",
    "    auto_model = LinearRegression()\n",
    "    selector = RFE(auto_model, 5, step=1)\n",
    "    model = selector.fit(X_train,y_train)\n",
    "    selector.ranking_\n",
    "    rfe_col = []\n",
    "    for x in range(len(X_train.columns)):\n",
    "        if selector.ranking_[x]<=limit:\n",
    "            rfe_col.append(X_train.columns[x])\n",
    "    print(len(rfe_col))\n",
    "    return rfe_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. apply to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 model 1 \"political satisfaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) selection of features by logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = reload()\n",
    "## selection of features by logic\n",
    "try1 = ['PB140: YEAR OF BIRTH',\n",
    " 'PB150: SEX',\n",
    " 'PB190: MARITAL STATUS',\n",
    " 'PE040: HIGHEST ISCED LEVEL ATTAINED',\n",
    " 'PL031: SELF-DEFINED CURRENT ECONOMIC STATUS',\n",
    " 'PH010: GENERAL HEALTH',\n",
    " 'PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME',\n",
    " 'PY090G++: SOCIAL BENEFITS',\n",
    " 'PD080: Internet connection for personal use at home','PW010: OVERALL LIFE SATISFACTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmodel (try1,'PW130: TRUST IN THE POLITICAL SYSTEM','yes' , 'yes', 'Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryclass_bin(try1,'PW130: TRUST IN THE POLITICAL SYSTEM',3, 'yes' , 'yes', 'Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tryclass_multi(xes,yli,nrbinx, nrbiny)\n",
    "tryclass_multi(try1,'PW130: TRUST IN THE POLITICAL SYSTEM',4,4, 'yes' , 'yes', 'Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  try2 only with prior features based on RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds=reload()\n",
    "try2 =generateRFE (ds[try1], ds['PW130: TRUST IN THE POLITICAL SYSTEM'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(2,6):\n",
    "    tryclass_multi(try1,'PW130: TRUST IN THE POLITICAL SYSTEM',x,x, 'yes' , 'yes', 'Normalizer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other way of binning:\n",
    "\n",
    "\n",
    "ds=reload()\n",
    "ds[yli]=ds[yli].apply(lambda x: 2 if (x <=2) & (x!=-1) else x)\n",
    "ds[yli]=ds[yli].apply(lambda x: 4 if (x ==3) & (x==4) else x)\n",
    "ds[yli]=ds[yli].apply(lambda x: 4 if (x ==3) & (x==4) else x)\n",
    "ds[yli] =ds[yli].apply(lambda x: 6 if ((x ==6) | (x==7)) else x)\n",
    "ds[yli].unique()\n",
    "ds[yli].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) based on RFE- all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) based on RFE- all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## based on RFE all columns\n",
    "try3 = ['PE010: CURRENT EDUCATION ACTIVITY',\n",
    " 'PL150: MANAGERIAL POSITION',\n",
    " 'PD050: Get-together with friends/family (relatives) for a drink/meal at least once a month',\n",
    " 'PD070: Spend a small amount of money each week on yourself',\n",
    " 'PW070: FEELING CALM AND PEACEFUL',\n",
    " 'PW220: PHYSICAL SECURITY']\n",
    "\n",
    "#try3\n",
    "xes = generateRFE(ds[columns], ds[yli], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## multi clas\n",
    "class_mul(xes, yli, 'yes','no','Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE with Dummy-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do rfe with dummy-features\n",
    "ds=reload()\n",
    "categorical= ['PB150: SEX', 'PB190: MARITAL STATUS',\n",
    "       'PB200: CONSENSUAL UNION', 'PB220A: CITIZENSHIP',\n",
    "       'PE010: CURRENT EDUCATION ACTIVITY',\n",
    "       'PL031: SELF-DEFINED CURRENT ECONOMIC STATUS',\n",
    "       'PL035: WORKED AT LEAST 1 HOUR DURING THE PREVIOUS WEEK',\n",
    "       'PL051: OCCUPATION (ISCO-08 (COM))', 'PL150: MANAGERIAL POSITION',\n",
    "        'PH030: LIMITATION IN ACTIVITIES BECAUSE OF HEALTH PROBLEMS',\n",
    "       'PH040: UNMET NEED FOR MEDICAL EXAMINATION OR TREATMENT',\n",
    "       'PH060: UNMET NEED FOR DENTAL EXAMINATION OR TREATMENT',\n",
    "       'PD020: Replace worn-out clothes by some new (not second-hand) ones',\n",
    "       'PD030: Two pairs of properly fitting shoes',\n",
    "       'PD050: Get-together with friends/family (relatives) for a drink/meal at least once a month',\n",
    "       'PD060: Regularly participate in a leisure activity',\n",
    "       'PD070: Spend a small amount of money each week on yourself',\n",
    "       'PD080: Internet connection for personal use at home',\n",
    "      ]\n",
    "#columns.remove(yli)\n",
    "create_dummy=set(columns).intersection(categorical)\n",
    "create_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy = pd.get_dummies(ds[columns], columns=create_dummy, drop_first=True)\n",
    "data_dummy.columns\n",
    "data_dummy\n",
    "generateRFE(data_dummy, ds[yli], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try4 = generateRFE(data_dummy, ds[yli], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dummy[try4]\n",
    "y= ds[yli]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### b) DecisionTree Classify\n",
    "\n",
    "dtc = DecisionTreeClassifier()#class_weight='balanced')#max_features=10,\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "acc = dtc.score(X_test, y_test)*100\n",
    "print(f\"Decision Tree Test Accuracy {round(acc, 2)}%\")\n",
    " \n",
    "\n",
    "#### c) Support Vector Maschine\n",
    "svm = SVC(decision_function_shape='ovo')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "acc = svm.score(X_test,y_test)*100\n",
    "print(f\"SVM Algorithm Test Accuracy {round(acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> Conclusion: No Model with accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 model 1 income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) selection of features by logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = reload()\n",
    "## selection of features by logic\n",
    "try1 = ['PB140: YEAR OF BIRTH',\n",
    " 'PB150: SEX',\n",
    " 'PB190: MARITAL STATUS',\n",
    " 'PE040: HIGHEST ISCED LEVEL ATTAINED',\n",
    " 'PL031: SELF-DEFINED CURRENT ECONOMIC STATUS',\n",
    " 'PL035: WORKED AT LEAST 1 HOUR DURING THE PREVIOUS WEEK',\n",
    " 'PL051: OCCUPATION (ISCO-08 (COM))',\n",
    " 'PL150: MANAGERIAL POSITION',\n",
    " 'PH010: GENERAL HEALTH',\n",
    " 'PW010: OVERALL LIFE SATISFACTION',\n",
    " 'PW080: FEELING DOWNHEARTED OR DEPRESSED',\n",
    " 'PW090: BEING HAPPY',\n",
    " 'PW180: HELP FROM OTHERS',\n",
    " 'PW190: TRUST IN OTHERS']\n",
    "\n",
    "ds=ds[ds['PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ds['PB140: YEAR OF BIRTH'],ds['PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME'])\n",
    "ds['PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmodel('PB140: YEAR OF BIRTH','PY010G_PY020G_PY021G_PY050G: EMPLOYEE INCOME','yes' , 'yes', 'Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryclass_bin(try1,'PW130: TRUST IN THE POLITICAL SYSTEM',3, 'yes' , 'yes', 'Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tryclass_multi(xes,yli,nrbinx, nrbiny)\n",
    "tryclass_multi(try1,'PW130: TRUST IN THE POLITICAL SYSTEM',4,4, 'yes' , 'yes', 'Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  try2 only with prior features based on RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds=reload()\n",
    "try2 =generateRFE (ds[try1], ds['PW130: TRUST IN THE POLITICAL SYSTEM'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(2,6):\n",
    "    tryclass_multi(try1,'PW130: TRUST IN THE POLITICAL SYSTEM',x,x, 'yes' , 'yes', 'Normalizer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other way of binning:\n",
    "\n",
    "\n",
    "ds=reload()\n",
    "ds[yli]=ds[yli].apply(lambda x: 2 if (x <=2) & (x!=-1) else x)\n",
    "ds[yli]=ds[yli].apply(lambda x: 4 if (x ==3) & (x==4) else x)\n",
    "ds[yli]=ds[yli].apply(lambda x: 4 if (x ==3) & (x==4) else x)\n",
    "ds[yli] =ds[yli].apply(lambda x: 6 if ((x ==6) | (x==7)) else x)\n",
    "ds[yli].unique()\n",
    "ds[yli].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) based on RFE- all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) based on RFE- all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## based on RFE all columns\n",
    "try3 = ['PE010: CURRENT EDUCATION ACTIVITY',\n",
    " 'PL150: MANAGERIAL POSITION',\n",
    " 'PD050: Get-together with friends/family (relatives) for a drink/meal at least once a month',\n",
    " 'PD070: Spend a small amount of money each week on yourself',\n",
    " 'PW070: FEELING CALM AND PEACEFUL',\n",
    " 'PW220: PHYSICAL SECURITY']\n",
    "\n",
    "#try3\n",
    "xes = generateRFE(ds[columns], ds[yli], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## multi clas\n",
    "class_mul(xes, yli, 'yes','no','Normalizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE with Dummy-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do rfe with dummy-features\n",
    "ds=reload()\n",
    "categorical= ['PB150: SEX', 'PB190: MARITAL STATUS',\n",
    "       'PB200: CONSENSUAL UNION', 'PB220A: CITIZENSHIP',\n",
    "       'PE010: CURRENT EDUCATION ACTIVITY',\n",
    "       'PL031: SELF-DEFINED CURRENT ECONOMIC STATUS',\n",
    "       'PL035: WORKED AT LEAST 1 HOUR DURING THE PREVIOUS WEEK',\n",
    "       'PL051: OCCUPATION (ISCO-08 (COM))', 'PL150: MANAGERIAL POSITION',\n",
    "        'PH030: LIMITATION IN ACTIVITIES BECAUSE OF HEALTH PROBLEMS',\n",
    "       'PH040: UNMET NEED FOR MEDICAL EXAMINATION OR TREATMENT',\n",
    "       'PH060: UNMET NEED FOR DENTAL EXAMINATION OR TREATMENT',\n",
    "       'PD020: Replace worn-out clothes by some new (not second-hand) ones',\n",
    "       'PD030: Two pairs of properly fitting shoes',\n",
    "       'PD050: Get-together with friends/family (relatives) for a drink/meal at least once a month',\n",
    "       'PD060: Regularly participate in a leisure activity',\n",
    "       'PD070: Spend a small amount of money each week on yourself',\n",
    "       'PD080: Internet connection for personal use at home',\n",
    "      ]\n",
    "#columns.remove(yli)\n",
    "create_dummy=set(columns).intersection(categorical)\n",
    "create_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummy = pd.get_dummies(ds[columns], columns=create_dummy, drop_first=True)\n",
    "data_dummy.columns\n",
    "data_dummy\n",
    "generateRFE(data_dummy, ds[yli], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try4 = generateRFE(data_dummy, ds[yli], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dummy[try4]\n",
    "y= ds[yli]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### b) DecisionTree Classify\n",
    "\n",
    "dtc = DecisionTreeClassifier()#class_weight='balanced')#max_features=10,\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "acc = dtc.score(X_test, y_test)*100\n",
    "print(f\"Decision Tree Test Accuracy {round(acc, 2)}%\")\n",
    " \n",
    "\n",
    "#### c) Support Vector Maschine\n",
    "svm = SVC(decision_function_shape='ovo')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "acc = svm.score(X_test,y_test)*100\n",
    "print(f\"SVM Algorithm Test Accuracy {round(acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> Conclusion: No Model with accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepwise as Backup\n",
    "# 1 Data Selection and Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. define features and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = ds['PW010: OVERALL LIFE SATISFACTION']\n",
    "features = ds[background]\n",
    "outcomelist='PW010: OVERALL LIFE SATISFACTION'\n",
    "featureslist=background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.merge(features, outcome, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 make lefts skewed X categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shouldbecategorical= main_list = list(set(data.columns)-set(categorical)-set([outcomelist]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical= ['PB150: SEX', 'PB190: MARITAL STATUS',\n",
    "       'PB200: CONSENSUAL UNION', 'PB220A: CITIZENSHIP',\n",
    "       'PE010: CURRENT EDUCATION ACTIVITY',\n",
    "       'PL031: SELF-DEFINED CURRENT ECONOMIC STATUS',\n",
    "       'PL035: WORKED AT LEAST 1 HOUR DURING THE PREVIOUS WEEK',\n",
    "       'PL051: OCCUPATION (ISCO-08 (COM))', 'PL150: MANAGERIAL POSITION',\n",
    "        'PH030: LIMITATION IN ACTIVITIES BECAUSE OF HEALTH PROBLEMS',\n",
    "       'PH040: UNMET NEED FOR MEDICAL EXAMINATION OR TREATMENT',\n",
    "       'PH060: UNMET NEED FOR DENTAL EXAMINATION OR TREATMENT',\n",
    "       'PD020: Replace worn-out clothes by some new (not second-hand) ones',\n",
    "       'PD030: Two pairs of properly fitting shoes',\n",
    "       'PD050: Get-together with friends/family (relatives) for a drink/meal at least once a month',\n",
    "       'PD060: Regularly participate in a leisure activity',\n",
    "       'PD070: Spend a small amount of money each week on yourself',\n",
    "       'PD080: Internet connection for personal use at home',\n",
    "      ]\n",
    "\n",
    "create_dummy=set(featureslist).intersection(categorical)\n",
    "\n",
    "data_dummy = pd.get_dummies(data, columns=create_dummy, drop_first=True)\n",
    "data_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dummy:\n",
    "data = data_dummy\n",
    "\n",
    "# not use dummy:\n",
    "#data = data =pd.merge(features, outcome, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>here decide to keep or drop nan in the outcome: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop nan\n",
    "#data = data[data[outcomelist]>=0]\n",
    "\n",
    "#reset \n",
    "#data = data =pd.merge(features, outcome, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCol=list(data.columns)\n",
    "XCol.remove(outcomelist)\n",
    "YCol=outcomelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[XCol]\n",
    "y= data[YCol]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€¢\timbalance checking (undersampling, oversamplingML umbalanced data lib)\n",
    "\n",
    "â€¢\tSplit --> X_tr, y_tr, / X_ts,  y_ts\n",
    "\n",
    "â€¢\tTry few models (with different algorithms) (<-- pipeline)\n",
    "\n",
    "    â€“\tInitialization\n",
    "\n",
    "    â€“\tFit / predict\n",
    "\n",
    "    â€“\tEvaluation (overfitting / underfitting)\n",
    "\n",
    "â€¢\tChoose best option based on requirements\n",
    "\n",
    "â€¢\tOptimize the model\n",
    "\n",
    "    â€“\tCross -validation\n",
    "\n",
    "    â€“\tTry few models (with same way to approach problem)\n",
    "\n",
    "        o\tInit\n",
    "\n",
    "        o\tFit.(predict)\n",
    "\n",
    "        o\tEvaluation\n",
    "\n",
    "    â€“\tHpyertuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Test for imbalancing in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.hist()\n",
    "\n",
    "## it is very imbalanced  --> bin the values bellow 5 and change *dont know\" to other value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.loc[(y['PW130: TRUST IN THE POLITICAL SYSTEM']==-1), 'PW130: TRUST IN THE POLITICAL SYSTEM']= X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>here decide how to bin y: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_binned=y.apply(lambda x: 4.5 if (x <=5) & (x!=-1) else x)\n",
    "y_binned =y_binned.apply(lambda x: 6.5 if ((x ==6) | (x==7)) else x)\n",
    "y_binned.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_binned.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### just to check correlation\n",
    "dset = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize =(10,5))\n",
    "corr = dset.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "sns.heatmap(corr, cmap='coolwarm', annot = False, linewidth=0.5, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>here decide to scale x or not and if yes which one: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_std.shape\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_minmax = scaler.fit_transform(X)\n",
    "X_minmax.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_minmax, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 run different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Prepare Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare interaction term\n",
    "for d in range(2):\n",
    "    interaction = PolynomialFeatures(degree = d, include_bias = False, interaction_only = True)\n",
    "    X_inter = interaction.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)  Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train,y_train)\n",
    "\n",
    "print(\"Intercept: \", lm.intercept_)\n",
    "print(\"Coef: \", lm.coef_)\n",
    "\n",
    "y_pred  = lm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)  Taylor (pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for k in range(1,8):\n",
    "poly_model = make_pipeline (StandardScaler(), PolynomialFeatures(degree=3, include_bias = False, interaction_only = True), LinearRegression())\n",
    "\n",
    "model = poly_model.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "print(poly_model.score(X_test, y_test))\n",
    "\n",
    "y_pred  = poly_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)  Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = DecisionTreeRegressor(random_state = 29)\n",
    "\n",
    "model = regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = regr.predict(X_test)\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = export_text(regr, feature_names=list(X.columns))\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rare cases you get a negative r squared value, you should probably rethink your regression analysis, especially if you are forcing an intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)  KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnr = KNeighborsRegressor(n_neighbors = 3)\n",
    "\n",
    "model = knnr.fit(X_train, y_train)  #fit the model\n",
    "y_pred = knnr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>huge means squared_error and negative r squared for binned and unbinned y\n",
    "     also failed with drop nan, but way better!\n",
    "    also failed with feature elimination\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. optimize recursive feature elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recursive feature elimination.\n",
    "# initialize an RFE model using the `auto_model` linear regression model. Set `n_features_to_select=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateTest(columns[:-20],outcomelist, 'yes', 'yes', 'yes', 'no')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and print the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateRFE(generateTest(columns[:-20],outcomelist, 'yes', 'yes', 'yes', 'no')[0],generateTest(columns[:-20],outcomelist, 'yes', 'yes', 'yes', 'no')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "auto_model = LinearRegression()\n",
    "selector = RFE(auto_model, 5, step=1)\n",
    "model = selector.fit(generateTest(columns[:-20],outcomelist, 'yes', 'yes', 'yes', 'no')[0],generateTest(columns[:-20],outcomelist, 'yes', 'yes', 'yes', 'no')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "selector.ranking_\n",
    "#selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xhere = generateTest(columns[:-20],outcomelist, 'yes', 'yes', 'yes', 'no')[0]\n",
    "rfe_col = []\n",
    "for x in range(len(Xhere.columns)):\n",
    "    if selector.ranking_[x]<=10:\n",
    "        rfe_col.append(Xhere.columns[x])\n",
    "print(len(rfe_col))\n",
    "rfe_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[columns]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X\n",
    "test['YY'] = ytogo\n",
    "plt.figure(figsize =(10,10))\n",
    "corr = X.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "sns.heatmap(corr, cmap='coolwarm', annot = False, linewidth=0.5, mask=mask)\n",
    "## --> run 2.2 split and 2.3 models again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[XCol]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA that will retain 99% of variance\n",
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "# ica = FastI-CA(n_components=0.99, whit-en=True)\n",
    "\n",
    "# Conduct PCA\n",
    "features_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= features_pca\n",
    "X.shape\n",
    "## --> run 2.2 split and 2.3 models again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change outcome variable to a 2 classification variable:\n",
    "# drop -1\n",
    "# based on ds_1\n",
    "data = ds_1\n",
    "\n",
    "data =data[data['PW130: TRUST IN THE POLITICAL SYSTEM']!=-1]\n",
    "data.shape\n",
    "ds_1.shape[0]-data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Y_class']= data['PW130: TRUST IN THE POLITICAL SYSTEM'].apply(lambda x: 1 if x>=8 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Y_class'].hist()\n",
    "data['Y_class'].value_counts()\n",
    "## --> balanced more or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCol=data.columns[:-2]\n",
    "YCol=data.columns[-1]\n",
    "\n",
    "print(len(XCol))\n",
    "print(YCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[XCol]\n",
    "y= data[YCol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train.shape\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = lr.score(X_test,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print( \"accuracy: \"  + str(round((conf[1,1]+conf[0,0])/ conf.sum()*100,2)))\n",
    "print( \"precision: \" +str(round((conf[0,0])/ (conf[1,0]+conf[0,0])*100,2)))\n",
    "\n",
    "conf\n",
    "\n",
    "tn,fp,fn,tp = confusion_matrix(y_test, y_pred).flatten()\n",
    "### it predicts all as 1..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) DecisionTree Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = dtc.score(X_test, y_test)*100\n",
    "print(f\"Decision Tree Test Accuracy {round(acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print( \"accuracy: \"  + str(round((conf[1,1]+conf[0,0])/ conf.sum()*100,2)))\n",
    "print( \"precision: \" +str(round((conf[0,0])/ (conf[1,0]+conf[0,0])*100,2)))\n",
    "\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## overfitting!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Support Vector Maschine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = svm.score(X_test,y_test)*100\n",
    "print(f\"SVM Algorithm Test Accuracy {round(acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print( \"accuracy: \"  + str(round((conf[1,1]+conf[0,0])/ conf.sum()*100,2)))\n",
    "print( \"precision: \" +str(round((conf[0,0])/ (conf[1,0]+conf[0,0])*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = knn.score(X_test, y_test)*100\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print( \"accuracy: \"  + str(round((conf[1,1]+conf[0,0])/ conf.sum()*100,2)))\n",
    "print( \"precision: \" +str(round((conf[0,0])/ (conf[1,0]+conf[0,0])*100,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
